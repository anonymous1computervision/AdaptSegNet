{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data, model_zoo\n",
    "from model.deeplab_multi import Res_Deeplab\n",
    "from dataset.cityscapes_dataset import cityscapesDataSet\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from dataset.gta5_dataset import GTA5DataSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
    "\n",
    "MODEL = 'DeepLab'\n",
    "BATCH_SIZE = 1\n",
    "ITER_SIZE = 1\n",
    "NUM_WORKERS = 4\n",
    "DATA_DIRECTORY = './data/GTA5'\n",
    "DATA_LIST_PATH = './dataset/gta5_list/train.txt'\n",
    "IGNORE_LABEL = 255\n",
    "INPUT_SIZE = '1280,720'\n",
    "DATA_DIRECTORY_TARGET = './data/Cityscapes/data'\n",
    "DATA_LIST_PATH_TARGET = './dataset/cityscapes_list/train.txt'\n",
    "INPUT_SIZE_TARGET = '1024,512'\n",
    "LEARNING_RATE = 2.5e-4\n",
    "MOMENTUM = 0.9\n",
    "NUM_CLASSES = 19\n",
    "NUM_STEPS = 250000\n",
    "NUM_STEPS_STOP = 100000  # early stopping\n",
    "POWER = 0.9\n",
    "RANDOM_SEED = 1234\n",
    "RESTORE_FROM = 'http://vllab.ucmerced.edu/ytsai/CVPR18/DeepLab_resnet_pretrained_init-f81d91e8.pth'\n",
    "SAVE_NUM_IMAGES = 2\n",
    "SAVE_PRED_EVERY = 5000\n",
    "SNAPSHOT_DIR = './snapshots/'\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "LEARNING_RATE_D = 1e-4\n",
    "LAMBDA_SEG = 0.1\n",
    "LAMBDA_ADV_TARGET1 = 0.0002\n",
    "LAMBDA_ADV_TARGET2 = 0.001\n",
    "\n",
    "TARGET = 'cityscapes'\n",
    "SET = 'train'\n",
    "palette = [128, 64, 128, 244, 35, 232, 70, 70, 70, 102, 102, 156, 190, 153, 153, 153, 153, 153, 250, 170, 30,\n",
    "           220, 220, 0, 107, 142, 35, 152, 251, 152, 70, 130, 180, 220, 20, 60, 255, 0, 0, 0, 0, 142, 0, 0, 70,\n",
    "           0, 60, 100, 0, 80, 100, 0, 0, 230, 119, 11, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask(mask):\n",
    "    # mask: numpy array of the mask\n",
    "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
    "    new_mask.putpalette(palette)\n",
    "\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set arg parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_arguments(args):\n",
    "    \"\"\"Parse all the arguments provided from the CLI.\n",
    "\n",
    "    Returns:\n",
    "      A list of parsed arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"DeepLab-ResNet Network\")\n",
    "    parser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY,\n",
    "                        help=\"Path to the directory containing the Cityscapes dataset.\")\n",
    "    parser.add_argument(\"--data-dir-target\", type=str, default=DATA_DIRECTORY_TARGET,\n",
    "                        help=\"Path to the directory containing the target dataset.\")\n",
    "    parser.add_argument(\"--data-list\", type=str, default=DATA_LIST_PATH,\n",
    "                        help=\"Path to the file listing the images in the dataset.\")\n",
    "    parser.add_argument(\"--model\", type=str, default=MODEL,\n",
    "                        help=\"available options : DeepLab\")\n",
    "    parser.add_argument(\"--target\", type=str, default=TARGET,\n",
    "                        help=\"available options : cityscapes\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=BATCH_SIZE,\n",
    "                        help=\"Number of images sent to the network in one step.\")\n",
    "    parser.add_argument(\"--iter-size\", type=int, default=ITER_SIZE,\n",
    "                        help=\"Accumulate gradients for ITER_SIZE iterations.\")\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=NUM_WORKERS,\n",
    "                        help=\"number of workers for multithread dataloading.\")\n",
    "    parser.add_argument(\"--ignore-label\", type=int, default=IGNORE_LABEL,\n",
    "                        help=\"The index of the label to ignore during the training.\")\n",
    "    parser.add_argument(\"--input-size\", type=str, default=INPUT_SIZE,\n",
    "                        help=\"Comma-separated string with height and width of source images.\")\n",
    "    parser.add_argument(\"--data-list-target\", type=str, default=DATA_LIST_PATH_TARGET,\n",
    "                        help=\"Path to the file listing the images in the target dataset.\")\n",
    "    parser.add_argument(\"--input-size-target\", type=str, default=INPUT_SIZE_TARGET,\n",
    "                        help=\"Comma-separated string with height and width of target images.\")\n",
    "    parser.add_argument(\"--is-training\", action=\"store_true\",\n",
    "                        help=\"Whether to updates the running means and variances during the training.\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=LEARNING_RATE,\n",
    "                        help=\"Base learning rate for training with polynomial decay.\")\n",
    "    parser.add_argument(\"--learning-rate-D\", type=float, default=LEARNING_RATE_D,\n",
    "                        help=\"Base learning rate for discriminator.\")\n",
    "    parser.add_argument(\"--lambda-seg\", type=float, default=LAMBDA_SEG,\n",
    "                        help=\"lambda_seg.\")\n",
    "    parser.add_argument(\"--lambda-adv-target1\", type=float, default=LAMBDA_ADV_TARGET1,\n",
    "                        help=\"lambda_adv for adversarial training.\")\n",
    "    parser.add_argument(\"--lambda-adv-target2\", type=float, default=LAMBDA_ADV_TARGET2,\n",
    "                        help=\"lambda_adv for adversarial training.\")\n",
    "    parser.add_argument(\"--momentum\", type=float, default=MOMENTUM,\n",
    "                        help=\"Momentum component of the optimiser.\")\n",
    "    parser.add_argument(\"--not-restore-last\", action=\"store_true\",\n",
    "                        help=\"Whether to not restore last (FC) layers.\")\n",
    "    parser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES,\n",
    "                        help=\"Number of classes to predict (including background).\")\n",
    "    parser.add_argument(\"--num-steps\", type=int, default=NUM_STEPS,\n",
    "                        help=\"Number of training steps.\")\n",
    "    parser.add_argument(\"--num-steps-stop\", type=int, default=NUM_STEPS_STOP,\n",
    "                        help=\"Number of training steps for early stopping.\")\n",
    "    parser.add_argument(\"--power\", type=float, default=POWER,\n",
    "                        help=\"Decay parameter to compute the learning rate.\")\n",
    "    parser.add_argument(\"--random-mirror\", action=\"store_true\",\n",
    "                        help=\"Whether to randomly mirror the inputs during the training.\")\n",
    "    parser.add_argument(\"--random-scale\", action=\"store_true\",\n",
    "                        help=\"Whether to randomly scale the inputs during the training.\")\n",
    "    parser.add_argument(\"--random-seed\", type=int, default=RANDOM_SEED,\n",
    "                        help=\"Random seed to have reproducible results.\")\n",
    "    parser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM,\n",
    "                        help=\"Where restore model parameters from.\")\n",
    "    parser.add_argument(\"--save-num-images\", type=int, default=SAVE_NUM_IMAGES,\n",
    "                        help=\"How many images to save.\")\n",
    "    parser.add_argument(\"--save-pred-every\", type=int, default=SAVE_PRED_EVERY,\n",
    "                        help=\"Save summaries and checkpoint every often.\")\n",
    "    parser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR,\n",
    "                        help=\"Where to save snapshots of the model.\")\n",
    "    parser.add_argument(\"--weight-decay\", type=float, default=WEIGHT_DECAY,\n",
    "                        help=\"Regularisation parameter for L2-loss.\")\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0,\n",
    "                        help=\"choose gpu device.\")\n",
    "    parser.add_argument(\"--set\", type=str, default=SET,\n",
    "                        help=\"choose adaptation set.\")\n",
    "    return parser.parse_args(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = set_arguments(\"--restore-from ./snapshots/selu-10k-20180524/GTA5_50000.pth --snapshot-dir ./snapshots/GTA2Cityscapes_multi --lambda-seg 0.1 --lambda-adv-target1 0.0002 --lambda-adv-target2 0.001\".split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=1, data_dir='./data/GTA5', data_dir_target='./data/Cityscapes/data', data_list='./dataset/gta5_list/train.txt', data_list_target='./dataset/cityscapes_list/train.txt', gpu=0, ignore_label=255, input_size='1280,720', input_size_target='1024,512', is_training=False, iter_size=1, lambda_adv_target1=0.0002, lambda_adv_target2=0.001, lambda_seg=0.1, learning_rate=0.00025, learning_rate_D=0.0001, model='DeepLab', momentum=0.9, not_restore_last=False, num_classes=19, num_steps=250000, num_steps_stop=100000, num_workers=4, power=0.9, random_mirror=False, random_scale=False, random_seed=1234, restore_from='./snapshots/selu-10k-20180524/GTA5_50000.pth', save_num_images=2, save_pred_every=5000, set='train', snapshot_dir='./snapshots/GTA2Cityscapes_multi', target='cityscapes', weight_decay=0.0005)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input and resize setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (1280, 720)\n",
    "input_size_target = (1024,512)\n",
    "interp = nn.Upsample(size=(input_size[1], input_size[0]), mode='bilinear')\n",
    "interp_target = nn.Upsample(size=(input_size_target[1], input_size_target[0]), mode='bilinear')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeplab model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create the model and start the evaluation process.\"\"\"\n",
    "gpu0 = args.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer5): Classifier_Module(\n",
       "    (conv2d_list): ModuleList(\n",
       "      (0): Conv2d(1024, 19, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (1): Conv2d(1024, 19, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "      (2): Conv2d(1024, 19, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "      (3): Conv2d(1024, 19, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "    )\n",
       "  )\n",
       "  (layer6): Classifier_Module(\n",
       "    (conv2d_list): ModuleList(\n",
       "      (0): Conv2d(2048, 19, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (1): Conv2d(2048, 19, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "      (2): Conv2d(2048, 19, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "      (3): Conv2d(2048, 19, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Res_Deeplab(num_classes=args.num_classes)\n",
    "\n",
    "if args.restore_from[:4] == 'http' :\n",
    "    saved_state_dict = model_zoo.load_url(args.restore_from)\n",
    "else:\n",
    "    saved_state_dict = torch.load(args.restore_from)\n",
    "model.load_state_dict(saved_state_dict)\n",
    "\n",
    "model.eval()\n",
    "model.cuda(gpu0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(\n",
    "    GTA5DataSet(args.data_dir, args.data_list, max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
    "                crop_size=input_size,\n",
    "                scale=args.random_scale, mirror=args.random_mirror, mean=IMG_MEAN),\n",
    "    batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetloader = data.DataLoader(cityscapesDataSet(args.data_dir_target, args.data_list_target,\n",
    "                                                     max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
    "                                                     crop_size=input_size_target,\n",
    "                                                     scale=False, mirror=args.random_mirror, mean=IMG_MEAN,\n",
    "                                                     set=args.set),\n",
    "                                   batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers,\n",
    "                                   pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_gen = enumerate(trainloader)\n",
    "targetloader_gen = enumerate(targetloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer source input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, batch = next(trainloader_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, _, _ = batch\n",
    "images = Variable(images).cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 720, 1280])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "img_var = Variable(images, volatile=True)\n",
    "# img_var = nn.no_grad(img_var)\n",
    "output1, output2 = model(img_var.cuda(gpu0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 19, 91, 161]), torch.Size([1, 19, 91, 161]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.shape, output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del img_var, output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer target input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, batch = next(targetloader_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _, name = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 1024])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get image sementic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "img_var = Variable(image, volatile=True)\n",
    "output1, output2 = model(img_var.cuda(gpu0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 65, 129])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\torch\\nn\\functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "output = interp(output1).cpu().data[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.transpose(1,2,0)\n",
    "output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_colorful_image = colorize_mask(output)\n",
    "get_image = Image.fromarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=P size=1280x720 at 0x1E9C0EBB978>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_colorful_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del img_var, output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discriminator check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.discriminator import FCDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCDiscriminator(\n",
       "  (conv1): Conv2d(19, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (classifier): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init D\n",
    "model_D1 = FCDiscriminator(num_classes=args.num_classes)\n",
    "model_D2 = FCDiscriminator(num_classes=args.num_classes)\n",
    "# model_D1.train()\n",
    "model_D1.cuda(args.gpu)\n",
    "# model_D2.train()\n",
    "model_D2.cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\torch\\nn\\functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "pred_target1, pred_target2 = model(Variable(image, volatile=True).cuda(gpu0))\n",
    "pred_target1 = interp_target(pred_target1)\n",
    "pred_target2 = interp_target(pred_target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 512, 1024])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_target1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 512, 1024])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pred_target1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "output_d = model_D1(F.softmax(pred_target1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 16, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pred_target1, pred_target2, output_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test my discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.xiao_discriminator import XiaoDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reload() argument must be a module",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-192bf15a7344>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXiaoDiscriminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\xiao\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reload() argument must be a module\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: reload() argument must be a module"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(XiaoDiscriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XiaoDiscriminator(\n",
       "  (conv1): Conv2d(19, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_resblock): ResBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace)\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_resblock): ResBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace)\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_resblock): ResBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace)\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_resblock): ResBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace)\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv5): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_resblock): ResBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace)\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (pad): ZeroPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "  (inner_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init D\n",
    "model_D1 = XiaoDiscriminator(num_classes=args.num_classes)\n",
    "model_D1.cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pred_target1, pred_target2 = model(Variable(image, volatile=True).cuda(gpu0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\torch\\nn\\functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "pred_target1 = interp_target(pred_target1)\n",
    "pred_target2 = interp_target(pred_target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPLAB\\Anaconda2\\envs\\xiao\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "output_d = model_D1(F.softmax(pred_target1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pred_target1, pred_target2, output_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
